{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Querying Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Get API keys from .env file\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "# AutoGen\n",
    "import autogen\n",
    "\n",
    "# LangChain\n",
    "from langchain.agents.agent_toolkits import create_python_agent\n",
    "from langchain.agents import load_tools, initialize_agent\n",
    "from langchain.agents import AgentType\n",
    "from langchain.tools.python.tool import PythonREPLTool\n",
    "from langchain.python import PythonREPL\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.agents import tool\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoGen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define helper methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define openai configurations\n",
    "openai_config_list = [\n",
    "    {\n",
    "        'model': 'gpt-3.5-turbo',                 # $0.03 for running the first request below (can't get live data, used placeholder data)\n",
    "        # 'model': 'gpt-4',                           # $0.33 for running the two requests below\n",
    "        'api_key': os.environ['OPENAI_API_KEY'],\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create AssistantAgent named \"assistant\"\n",
    "assistant = autogen.AssistantAgent(\n",
    "    name=\"assistant\",\n",
    "    llm_config={\n",
    "        \"seed\": 42,                             # Seed for caching/reproducibility\n",
    "        \"config_list\": openai_config_list,             # OpenAI API configurations\n",
    "        \"temperature\": 0,                       # Randomness, 0 means no randomness\n",
    "    }                                           # Config for autogen's enhanced inference API\n",
    ")\n",
    "\n",
    "# Create UserProxyAgent named \"user_proxy\"\n",
    "user_proxy = autogen.UserProxyAgent(\n",
    "    name=\"user_proxy\",\n",
    "    human_input_mode=\"NEVER\",                   # NEVER, ALWAYS, or TERMINATE (Recommendation; 1 question: NEVER, multiple followup questions: TERMINATE)\n",
    "    max_consecutive_auto_reply=10,              # Max number of auto replies\n",
    "    is_termination_msg=lambda x: x.get(\"content\", \"\").rstrip().endswith(\"TERMINATE\"),   # Termination condition\n",
    "    code_execution_config={\n",
    "        \"work_dir\": \"coding\",                   # Working directory for code execution (where generated files are stored)\n",
    "        \"use_docker\": False,                    # Set to True or image name like \"python:3\" to use docker\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sum all numbers in a range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assistant receives message from user_proxy\n",
    "user_proxy.initiate_chat(\n",
    "    assistant,\n",
    "    message=\"\"\"Sum all the numbers from 0 to 10.\"\"\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sort array in descending order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assistant receives message from user_proxy\n",
    "user_proxy.initiate_chat(\n",
    "    assistant,\n",
    "    message=\"\"\"Sort the array [1, 3, 2, 4, 5, 7] in descending order.\"\"\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Describe Djikstra's algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assistant receives message from user_proxy\n",
    "user_proxy.initiate_chat(\n",
    "    assistant,\n",
    "    message=\"\"\"Describe Djikstra's algorithm using at most 200 words.\"\"\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stock price comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assistant receives message from user_proxy\n",
    "user_proxy.initiate_chat(\n",
    "    assistant,\n",
    "    message=\"\"\"What date is today? Compare the year-to-date gain for META and TESLA.\"\"\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Followup question:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_proxy.send(\n",
    "    recipient=assistant,\n",
    "    message=\"\"\"Plot a chart of their stock price change YTD and save to stock_price_ytd.png.\"\"\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define helper methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the model\n",
    "llm_model = \"gpt-3.5-turbo\"\n",
    "llm = ChatOpenAI(temperature=0, model=llm_model)\n",
    "\n",
    "# Create a custom tool\n",
    "@tool\n",
    "def time(text: str) -> str:\n",
    "    \"\"\"Returns todays date, use this for any \\\n",
    "    questions related to knowing todays date. \\\n",
    "    The input should always be an empty string, \\\n",
    "    and this function will always return todays \\\n",
    "    date - any date mathmatics should occur \\\n",
    "    outside this function.\"\"\"\n",
    "    return str(date.today())\n",
    "\n",
    "# Give the model access to llm-math and wikipedia\n",
    "tools = load_tools([\"llm-math\",\"wikipedia\"], llm=llm)\n",
    "\n",
    "# Give the model access to the custom tool\n",
    "tools = tools + [time]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an agent with access to llm_math, wikipedia and a custom tool\n",
    "agent= initialize_agent(\n",
    "    tools, \n",
    "    llm, \n",
    "    agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    handle_parsing_errors=True,\n",
    "    verbose = True)\n",
    "\n",
    "# Create a Python agent\n",
    "python_agent = create_python_agent(\n",
    "    llm,\n",
    "    tool=PythonREPLTool(),\n",
    "    handle_parsing_errors=True,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sum all numbers in a range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agent(\"\"\"Sum all the numbers from 0 to 10.\"\"\")                  # GPT-3.5-turbo: Wrong answer + Confused by output format, endless loop\n",
    "python_agent(\"\"\"Sum all the numbers from 0 to 10.\"\"\")           # GPT-3.5-turbo: Correct answer + Very fast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sort array in descending order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agent(\"\"\"Sort the array [1, 3, 2, 4, 5, 7] in descending order.\"\"\")             # GPT-3.5-turbo: Unable to complete the request (Correct answer) + Confused by output format, endless loop\n",
    "python_agent(\"\"\"Sort the array [1, 3, 2, 4, 5, 7] in descending order.\"\"\")      # GPT-3.5-turbo: Correct answer + Pretty fast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Describe Djikstra's algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent(\"\"\"Describe Djikstra's algorithm using at most 200 words.\"\"\")             # GPT-3.5-turbo: Unable to complete the request + Confused by output format, endless loop\n",
    "# python_agent(\"\"\"Describe Djikstra's algorithm using at most 200 words.\"\"\")      # GPT-3.5-turbo: Unable to complete the request + Confused by output format, crashes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stock price comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agent(\"\"\"What date is today? Compare the year-to-date gain for META and TESLA.\"\"\")          # GPT-3.5-turbo: Unable to complete the request + Uses Wikipedia to look for stock prices (other than that, correct approach)\n",
    "python_agent(\"\"\"What date is today? Compare the year-to-date gain for META and TESLA.\"\"\")   # GPT-3.5-turbo: Unable to complete the request + Can't import `datetime`, endless loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Followup question (must be provided in initial question):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agent(\"\"\"What date is today? Compare the year-to-date gain for META and TESLA. \n",
    "#       Plot a chart of their stock price change YTD and save to stock_price_ytd.png.\"\"\")          # GPT-3.5-turbo: Unable to complete the request + Uses Wikipedia to look for stock prices (other than that, correct approach)\n",
    "\n",
    "python_agent(\"\"\"What date is today? Compare the year-to-date gain for META and TESLA. \n",
    "             Plot a chart of their stock price change YTD and save to stock_price_ytd.png.\"\"\")   # GPT-3.5-turbo: Unable to complete the request + Makes correct imports, but doesn't look for stock prices\n",
    "                                                                                                 # GPT-3.5-turbo: Correct answer + Pretty fast (With handle_parse_errors=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentchat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
